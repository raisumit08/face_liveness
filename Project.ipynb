{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c4f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import f_utils\n",
    "import dlib\n",
    "import numpy as np\n",
    "import questions\n",
    "import random\n",
    "from profile_detection import f_detector\n",
    "from emotion_detection import f_emotion_detection\n",
    "from blink_detection import f_blink_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "254afb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frontal_face_detector    = dlib.get_frontal_face_detector()\n",
    "profile_detector         = f_detector.detect_face_orientation()\n",
    "emotion_detector         = f_emotion_detection.predict_emotions()\n",
    "blink_detector           = f_blink_detection.eye_blink_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58545eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_liveness(im,COUNTER=0,TOTAL=0):\n",
    "    \n",
    "    gray = gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # face detection\n",
    "    rectangles = frontal_face_detector(gray, 0)\n",
    "    boxes_face = f_utils.convert_rectangles2array(rectangles,im)\n",
    "    if len(boxes_face)!=0:\n",
    "        \n",
    "        areas = f_utils.get_areas(boxes_face)\n",
    "        index = np.argmax(areas)\n",
    "        rectangles = rectangles[index]\n",
    "        boxes_face = [list(boxes_face[index])]\n",
    "\n",
    "        # ------------------- emotion_detection ---------------------------------------\n",
    "        '''\n",
    "        input:\n",
    "            - imagen RGB\n",
    "            - boxes_face: [[579, 170, 693, 284]]\n",
    "        output:\n",
    "            - status: \"ok\"\n",
    "            - emotion: ['happy'] or ['neutral'] ...\n",
    "            - box: [[579, 170, 693, 284]]\n",
    "        '''\n",
    "        _,emotion = emotion_detector.get_emotion(im,boxes_face)\n",
    "        # ----------------------- blink_detection -----------------------------------\n",
    "        '''\n",
    "        input:\n",
    "            - imagen gray\n",
    "            - rectangles\n",
    "        output:\n",
    "            - status: \"ok\"\n",
    "            - COUNTER: # frames consecutivos por debajo del umbral\n",
    "            - TOTAL: # de parpadeos\n",
    "        '''\n",
    "        COUNTER,TOTAL = blink_detector.eye_blink(gray,rectangles,COUNTER,TOTAL)\n",
    "    else:\n",
    "        boxes_face = []\n",
    "        emotion = []\n",
    "        TOTAL = 0\n",
    "        COUNTER = 0\n",
    "\n",
    "    # ---------------------------- profile_detection---------------------------------\n",
    "    '''\n",
    "    input:\n",
    "        - imagen gray\n",
    "    output:\n",
    "        - status: \"ok\"\n",
    "        - profile: [\"right\"] or [\"left\"]\n",
    "        - box: [[579, 170, 693, 284]]\n",
    "    '''\n",
    "    box_orientation, orientation = profile_detector.face_orientation(gray)\n",
    "\n",
    "    # -------------------------------------- output ---------------------------------------\n",
    "    output = {\n",
    "        'box_face_frontal': boxes_face,\n",
    "        'box_orientation': box_orientation,\n",
    "        'emotion': emotion,\n",
    "        'orientation': orientation,\n",
    "        'total_blinks': TOTAL,\n",
    "        'count_blinks_consecutives': COUNTER\n",
    "    }\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1fc390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 21:29:26.031050: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# camera access given\n",
    "cv2.namedWindow('liveness detection')\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# parameters \n",
    "COUNTER, TOTAL = 0,0\n",
    "counter_ok_questions = 0\n",
    "counter_ok_consecutives = 0\n",
    "limit_consecutives = 1\n",
    "limit_questions = 3\n",
    "counter_try = 0\n",
    "limit_try = 50 \n",
    "\n",
    "def show_image(cam,text,color = (0,0,255)):\n",
    "    ret, im = cam.read()\n",
    "    im = imutils.resize(im, width=720)\n",
    "    im = cv2.flip(im, 1)\n",
    "    cv2.putText(im,text,(10,50),cv2.FONT_HERSHEY_COMPLEX,1,color,2)\n",
    "    return im\n",
    "\n",
    "\n",
    "for i_questions in range(0,limit_questions):\n",
    "    index_question = random.randint(0,5)\n",
    "    question = questions.question_bank(index_question)\n",
    "    \n",
    "    im = show_image(cam,question)\n",
    "    cv2.imshow('liveness_detection',im)\n",
    "    if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "    for i_try in range(limit_try):\n",
    "        \n",
    "        ret, im = cam.read()\n",
    "        im = imutils.resize(im, width=720)\n",
    "        im = cv2.flip(im, 1)\n",
    "        # <----------------------- ingestar data \n",
    "        TOTAL_0 = TOTAL\n",
    "        out_model = detect_liveness(im,COUNTER,TOTAL_0)\n",
    "        TOTAL = out_model['total_blinks']\n",
    "        COUNTER = out_model['count_blinks_consecutives']\n",
    "        dif_blink = TOTAL-TOTAL_0\n",
    "        if dif_blink > 0:\n",
    "            blinks_up = 1\n",
    "        else:\n",
    "            blinks_up = 0\n",
    "\n",
    "        challenge_res = questions.challenge_result(question, out_model,blinks_up)\n",
    "\n",
    "        im = show_image(cam,question)\n",
    "        cv2.imshow('liveness_detection',im)\n",
    "        if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "            break \n",
    "\n",
    "        if challenge_res == \"pass\":\n",
    "            im = show_image(cam,question+\" : ok\")\n",
    "            cv2.imshow('liveness_detection',im)\n",
    "            if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            counter_ok_consecutives += 1\n",
    "            if counter_ok_consecutives == limit_consecutives:\n",
    "                counter_ok_questions += 1\n",
    "                counter_try = 0\n",
    "                counter_ok_consecutives = 0\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        elif challenge_res == \"fail\":\n",
    "            counter_try += 1\n",
    "            show_image(cam,question+\" : fail\")\n",
    "        elif i_try == limit_try-1:\n",
    "            break\n",
    "            \n",
    "\n",
    "    if counter_ok_questions ==  limit_questions:\n",
    "        while True:\n",
    "            im = show_image(cam,\"LIVENESS SUCCESSFUL\",color = (0,255,0))\n",
    "            cv2.imshow('liveness_detection',im)\n",
    "            if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "                break\n",
    "    elif i_try == limit_try-1:\n",
    "        while True:\n",
    "            im = show_image(cam,\"LIVENESS FAIL\")\n",
    "            cv2.imshow('liveness_detection',im)\n",
    "            if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "                break\n",
    "        break \n",
    "\n",
    "    else:\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
